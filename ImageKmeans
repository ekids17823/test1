import os
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Tuple
from concurrent.futures import ThreadPoolExecutor
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from tensorflow.keras.applications import ResNet50, MobileNetV2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input
import matplotlib.pyplot as plt
import plotly.express as px
from tqdm import tqdm
import logging

# 配置日志
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# 配置参数
class Config:
    IMG_SIZE = (224, 224)
    BATCH_SIZE = 32
    N_CLUSTERS = 2
    ALLOWED_EXTENSIONS = ('.jpg', '.jpeg', '.png')
    MODEL_NAME = 'mobilenetv2'  # 可选 'resnet50' 或 'mobilenetv2'
    OUTPUT_DIR = Path('output')
    FEATURES_CACHE = Path('features.npy')
    LABELS_CACHE = Path('labels.npy')
    
    # 创建输出目录
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# 初始化模型
def init_model() -> Tuple[any, int]:
    """根据配置选择并初始化特征提取模型"""
    if Config.MODEL_NAME == 'mobilenetv2':
        model = MobileNetV2(weights='imagenet', 
                           include_top=False, 
                           pooling='avg',
                           input_shape=(*Config.IMG_SIZE, 3))
        feature_dim = 1280
    else:  # 默认使用ResNet50
        model = ResNet50(weights='imagenet', 
                        include_top=False, 
                        pooling='avg')
        feature_dim = 2048
    return model, feature_dim

def batch_extract_features(img_paths: List[Path], model: any) -> np.ndarray:
    """批量提取特征并处理异常"""
    batch_images = []
    valid_paths = []
    
    for img_path in img_paths:
        try:
            img = image.load_img(img_path, target_size=Config.IMG_SIZE)
            img_data = image.img_to_array(img)
            batch_images.append(img_data)
            valid_paths.append(img_path)
        except Exception as e:
            logging.warning(f"无法加载图片 {img_path}: {str(e)}")
    
    if not batch_images:
        return np.array([]), []
    
    batch_array = preprocess_input(np.array(batch_images))
    features = model.predict(batch_array, batch_size=Config.BATCH_SIZE)
    return features, valid_paths

def process_dataset(folders: List[Tuple[Path, str]]) -> Tuple[List[str], List[str], np.ndarray]:
    """处理整个数据集并返回特征"""
    model, feature_dim = init_model()
    all_features = np.zeros((0, feature_dim))
    all_labels = []
    all_paths = []
    
    # 获取所有有效图片路径
    img_paths = []
    for folder, label in folders:
        img_paths.extend([
            (p, label) 
            for p in folder.glob('*') 
            if p.suffix.lower() in Config.ALLOWED_EXTENSIONS
        ])
    
    # 使用线程池并行处理
    with ThreadPoolExecutor() as executor:
        futures = []
        for i in range(0, len(img_paths), Config.BATCH_SIZE):
            batch = img_paths[i:i+Config.BATCH_SIZE]
            futures.append(executor.submit(process_batch, batch, model))
        
        for future in tqdm(futures, desc="Processing batches"):
            batch_features, batch_labels, batch_paths = future.result()
            if batch_features.size > 0:
                all_features = np.vstack([all_features, batch_features])
                all_labels.extend(batch_labels)
                all_paths.extend(batch_paths)
    
    # 保存特征缓存
    np.save(Config.FEATURES_CACHE, all_features)
    np.save(Config.LABELS_CACHE, np.array([all_labels, all_paths]))
    
    return all_paths, all_labels, all_features

def process_batch(batch: List[Tuple[Path, str]], model: any) -> Tuple[np.ndarray, List[str], List[str]]:
    """处理单个批次的数据"""
    paths, labels = zip(*batch)
    features, valid_paths = batch_extract_features(paths, model)
    valid_labels = [label for path, label in zip(paths, labels) if path in valid_paths]
    return features, valid_labels, [str(p) for p in valid_paths]

# 配置数据集路径 (根据实际路径修改)
dataset_config = [
    (Path('dataset/cats'), 'cat')
]

# 验证数据集路径
for folder, _ in dataset_config:
    if not folder.exists():
        raise FileNotFoundError(f"数据集目录不存在: {folder}")

# 处理数据集并获取特征
file_paths, labels, features = process_dataset(dataset_config)

if len(features) == 0:
    raise ValueError("没有找到有效的图片文件，请检查数据集路径和文件格式")

# K-means 分群
kmeans = KMeans(n_clusters=Config.N_CLUSTERS, random_state=42)
clusters = kmeans.fit_predict(features)

# 计算轮廓系数
silhouette_avg = silhouette_score(features, clusters)
logging.info(f"轮廓系数: {silhouette_avg:.2f}")

# 降維以利視覺化
pca = PCA(n_components=2)
reduced_features = pca.fit_transform(features)

# 輸出 Excel
df = pd.DataFrame({
    'FileName': file_paths,
    'Label': labels,
    'Cluster': clusters
})
df.to_excel('clustering_results.xlsx', index=False)

# 繪製 2D 分布圖
plt.figure(figsize=(12, 8))
plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=clusters, 
          cmap='tab20', s=50, alpha=0.8, edgecolors='w')

plt.title('Cat Image Clustering Pattern Analysis', fontsize=14, pad=20)
plt.xlabel('Principal Component 1', fontsize=12)
plt.ylabel('Principal Component 2', fontsize=12)
plt.colorbar(label='Cluster Group')

# 添加網格和美化樣式
plt.grid(True, linestyle='--', alpha=0.6)
plt.gca().set_facecolor('#f5f5f5')

# 保存高質量圖片
plt.savefig('clustering_plot.png', dpi=300, bbox_inches='tight')
plt.show()
